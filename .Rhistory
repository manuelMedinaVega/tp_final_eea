for(i in 1:19) {
pred <- predict(best.fit, Hitters[folds == j, ], id = i)
cv.errors[j, i] <- mean((Hitters$Salary[folds == j] - pred) ^ 2)
}
}
predict.regsubsets <- function(object, newdata, id, ...) {
form <- as.formula(object$call[[2]])
mat <- model.matrix(form, newdata)
coefi <- coef(object, id = id)
xvars <- names(coefi)
mat[, xvars] %*% coefi
}
for(j in 1:k) {
best.fit <- regsubsets(Salary ~ ., data = Hitters[folds != j, ], nvmax = 19)
for(i in 1:19) {
pred <- predict(best.fit, Hitters[folds == j, ], id = i)
cv.errors[j, i] <- mean((Hitters$Salary[folds == j] - pred) ^ 2)
}
}
k <- 10
n <- nrow(Hitters)
set.seed(1)
folds <- sample(rep(1:k, length = n))
cv.errors <- matrix(NA, k, 19, dimnames = list(NULL, paste(1:19)))
cv.errors
for(j in 1:k) {
best.fit <- regsubsets(Salary ~ ., data = Hitters[folds != j, ], nvmax = 19)
for(i in 1:19) {
pred <- predict(best.fit, Hitters[folds == j, ], id = i)
cv.errors[j, i] <- mean((Hitters$Salary[folds == j] - pred) ^ 2)
}
}
predict.regsubsets <- function(object, newdata, id, ...) {
form <- as.formula(object$call[[2]])
mat <- model.matrix(form, newdata)
coefi <- coef(object, id = id)
xvars <- names(coefi)
mat[, xvars] %*% coefi
}
k <- 10
n <- nrow(Hitters)
set.seed(1)
folds <- sample(rep(1:k, length = n))
cv.errors <- matrix(NA, k, 19, dimnames = list(NULL, paste(1:19)))
cv.errors
for(j in 1:k) {
best.fit <- regsubsets(Salary ~ ., data = Hitters[folds != j, ], nvmax = 19)
for(i in 1:19) {
pred <- predict(best.fit, Hitters[folds == j, ], id = i)
cv.errors[j, i] <- mean((Hitters$Salary[folds == j] - pred) ^ 2)
}
}
View(cv.errors)
View(predict.regsubsets)
library(ISLR2)
library(leaps)
View(Hitters)
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
#removemos nas
Hitters <- na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
#best subset, por default se queda con 8
regfit.full <- regsubsets(Salary ~ ., Hitters)
summary(regfit.full)
#indicamos el máximo de variables posibles
regfit.full <- regsubsets(Salary ~ ., Hitters, nvmax = 19)
reg.summary <- summary(regfit.full)
reg.summary
#ver los r cuadrados
names(reg.summary)
reg.summary$rsq
#ploteamos el RSS y el R2 ajustado
par(mfrow = c(2, 2))
plot(reg.summary$rss, xlab = "Number of variables", ylab = "RSS", type = "l")
library(ISLR2)
library(leaps)
View(Hitters)
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
#removemos nas
Hitters <- na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
#best subset, por default se queda con 8
regfit.full <- regsubsets(Salary ~ ., Hitters)
summary(regfit.full)
#indicamos el máximo de variables posibles
regfit.full <- regsubsets(Salary ~ ., Hitters, nvmax = 19)
reg.summary <- summary(regfit.full)
reg.summary
#ver los r cuadrados
names(reg.summary)
reg.summary$rsq
#ploteamos el RSS y el R2 ajustado
par(mfrow = c(2, 2))
plot(reg.summary$rss, xlab = "Number of variables", ylab = "RSS", type = "l")
#ploteamos el RSS y el R2 ajustado
par(mfrow = c(2, 2))
plot(reg.summary$rss, xlab = "Number of variables", ylab = "RSS", type = "l")
plot(reg.summary$adjr2, xlab = "Number of variables", ylab = "Adjusted RSq",
type = "l")
#ploteamos el RSS y el R2 ajustado
par(mfrow = c(2, 2))
plot(reg.summary$rss, xlab = "Number of variables", ylab = "RSS", type = "l")
#ploteamos el RSS y el R2 ajustado
par(mfrow = c(2, 2))
plot(reg.summary$rss, xlab = "Number of variables", ylab = "RSS", type = "l")
plot(reg.summary$adjr2, xlab = "Number of variables", ylab = "Adjusted RSq",
type = "l")
library(ISLR2)
library(leaps)
View(Hitters)
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
#removemos nas
Hitters <- na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
#best subset, por default se queda con 8
regfit.full <- regsubsets(Salary ~ ., Hitters)
summary(regfit.full)
#indicamos el máximo de variables posibles
regfit.full <- regsubsets(Salary ~ ., Hitters, nvmax = 19)
reg.summary <- summary(regfit.full)
reg.summary
#ver los r cuadrados
names(reg.summary)
reg.summary$rsq
#ploteamos el RSS y el R2 ajustado
par(mfrow = c(2, 2))
plot(reg.summary$rss, xlab = "Number of variables", ylab = "RSS", type = "l")
plot(reg.summary$adjr2, xlab = "Number of variables", ylab = "Adjusted RSq",
type = "l")
which.max(reg.summary$adjr2)
points(11, reg.summary$adjr2[11], col = "red", cex = 2, pch = 20)
plot(reg.summary$cp, xlab = "Number of variables", ylab = "Cp", type = "l")
which.min(reg.summary$cp)
points(10, reg.summary$cp[10], col = "red", cex = 2, pch = 20)
plot(reg.summary$bic, xlab = "Number of variables", ylab = "BIC", type = "l")
which.min(reg.summary$bic)
points(6, reg.summary$bic[6], col = "red", cex = 2, pch = 20)
plot(regfit.full, scale = "r2")
library(ISLR2)
library(leaps)
View(Hitters)
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
#removemos nas
Hitters <- na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
#best subset, por default se queda con 8
regfit.full <- regsubsets(Salary ~ ., Hitters)
summary(regfit.full)
#indicamos el máximo de variables posibles
regfit.full <- regsubsets(Salary ~ ., Hitters, nvmax = 19)
reg.summary <- summary(regfit.full)
reg.summary
#ver los r cuadrados
names(reg.summary)
reg.summary$rsq
#ploteamos el RSS y el R2 ajustado
par(mfrow = c(2, 2))
plot(reg.summary$rss, xlab = "Number of variables", ylab = "RSS", type = "l")
dev.off()
#ploteamos el RSS y el R2 ajustado
par(mfrow = c(2, 2))
plot(reg.summary$rss, xlab = "Number of variables", ylab = "RSS", type = "l")
plot(reg.summary$adjr2, xlab = "Number of variables", ylab = "Adjusted RSq",
type = "l")
#ploteamos el RSS y el R2 ajustado
par(mfrow = c(2, 2))
plot(reg.summary$rss, xlab = "Number of variables", ylab = "RSS", type = "l")
plot(reg.summary$adjr2, xlab = "Number of variables", ylab = "Adjusted RSq",
type = "l")
which.max(reg.summary$adjr2)
points(11, reg.summary$adjr2[11], col = "red", cex = 2, pch = 20)
plot(reg.summary$cp, xlab = "Number of variables", ylab = "Cp", type = "l")
which.min(reg.summary$cp)
points(10, reg.summary$cp[10], col = "red", cex = 2, pch = 20)
plot(reg.summary$bic, xlab = "Number of variables", ylab = "BIC", type = "l")
which.min(reg.summary$bic)
points(6, reg.summary$bic[6], col = "red", cex = 2, pch = 20)
plot(regfit.full, scale = "r2")
plot(regfit.full, scale = "adjr2")
plot(regfit.full, scale = "Cp")
plot(regfit.full, scale = "bic")
set.seed(1)
train <- sample(c(TRUE, FALSE), nrow(Hitters), replace = TRUE)
test <- (!train)
regfit.best <- regsubsets(Salary ~ ., data = Hitters[train, ], nvmax = 19)
#compute the validation set error for the best model of each model size
#we first make a model matrix from the test data
test.mat <- model.matrix(Salary ~ ., data = Hitters[test, ])
val.errors <- rep(NA, 19)
for (i in 1:19) {
coefi <- coef(regfit.best, id = i)
pred <- test.mat[, names(coefi)] %*% coefi
val.errors[i] <- mean((Hitters$Salary[test] - pred) ^ 2)
}
val.errors
which.min(val.errors)
coef(regfit.best, 7)
predict.regsubsets <- function(object, newdata, id, ...) {
form <- as.formula(object$call[[2]])
mat <- model.matrix(form, newdata)
coefi <- coef(object, id = id)
xvars <- names(coefi)
mat[, xvars] %*% coefi
}
regfit.best <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19)
coef(regfit.best, 7)
k <- 10
n <- nrow(Hitters)
set.seed(1)
folds <- sample(rep(1:k, length = n))
cv.errors <- matrix(NA, k, 19, dimnames = list(NULL, paste(1:19)))
cv.errors
for(j in 1:k) {
best.fit <- regsubsets(Salary ~ ., data = Hitters[folds != j, ], nvmax = 19)
for(i in 1:19) {
pred <- predict(best.fit, Hitters[folds == j, ], id = i)
cv.errors[j, i] <- mean((Hitters$Salary[folds == j] - pred) ^ 2)
}
}
mean.cv.errors <- apply(cv.errors, 2, mean)
mean.cv.errors
#cross validation selects a 10-variable model.
reg.best <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19)
coef(reg.best, 10)
seq(10, -2, length = 100)
library(ISLR2)
library(leaps)
View(Hitters)
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
#removemos nas
Hitters <- na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
library(pls)
set.seed(123)
pcr.fit <- pcr(Salary ~ ., data = Hitters, scale = TRUE, validation = "CV")
summary(pcr.fit)
validationplot(pcr.fit, val.type = "MSEP")
validationplot(pcr.fit, val.type = "MSEP")
validationplot(pcr.fit, val.type = "MSEP")
validationplot(pcr.fit, val.type = "MSEP")
set.seed(2)
pcr.fit <- pcr(Salary ~ ., data = Hitters, scale = TRUE, validation = "CV")
summary(pcr.fit)
validationplot(pcr.fit, val.type = "MSEP")
nrow(Hitters)
set.seed(1)
train <- sample(1:nrow(Hitters), nrow(Hitters) / 2)
test <- (-train)
pcr.fit <- pcr(Salary ~ ., data = Hitters, subset = train, scale = TRUE, validation = "CV" )
validationplot(pcr.fit, val.type = "MSEP")
pcr.pred <- predict(pcr.fit, x[test, ], ncomp = 5)
mean((pcr.pred - y.test) ^ 2)
pcr.pred <- predict(pcr.fit, Hitters[test, ], ncomp = 5)
mean((pcr.pred - y.test) ^ 2)
Hitters
Hitters[test, ]
mean((pcr.pred - Hitters[test, Salary]) ^ 2)
mean((pcr.pred - Hitters$Salary[test, ]) ^ 2)
Hitters[test, ]
Hitters[test, c("Salary")]
mean((pcr.pred - Hitters[test, c("Salary")]) ^ 2)
pcr.fit <- pcr(Salary ~ ., data = Hitters, scale = TRUE, ncomp = 5)
summary(pcr.fit)
library(tidyverse)
library(tidymodels)
library(GGally)
library(cowplot)
library(GGally)
library(RColorBrewer)
nba = read_csv(" nba_player_stats_salary_2019_2020.csv")
nba = read_csv("nba_player_stats_salary_2019_2020.csv")
c
nba = read_csv("nba_player_stats_salary_2019_2020.csv")
setwd("~/m_d_m/eea/tp2")
nba = read_csv("nba_player_stats_salary_2019_2020.csv")
View(nba)
nba <- na.omit(nba)
dim(nba)
nba <- nba %>% rename(salary = mean_salary_2019_2020) %>%
mutate(Pos = str_remove(string = Pos, pattern = "\\-.*"))
dim(nba)
View(nba)
nba %>%
select_if(is.numeric) %>% # selección variables numéricas
ggcorr(., layout.exp = 5, hjust = 1, size = 3.5, nbreaks = 5, color = "grey50") + # graficamos correlacion pearson
labs(title='Correlograma de variables cuantitativas')
# Eliminamos jugador y equipo
nba = nba %>% select(-c(Player, Tm))
# Modelo lineal
modelo_lineal = nba %>% lm(formula = salary~., data = .)
summary(modelo_lineal)
nba_scaled = nba %>% mutate_at(vars(-Pos), scale)
# Nuevo modelo lineal
modelo_lineal_scal = nba_scaled %>% lm(formula = salary~., data = .)
modelos_lineales = list(lineal = modelo_lineal, lineal_escalado = modelo_lineal_scal)
map_dfr(.x = modelos_lineales, .f = glance, .id="modelo") %>%
select(modelo, r.squared, adj.r.squared, p.value)
set.seed(123)
pcr.fit.nba <- pcr(Salary ~ ., data = nba_scaled, scale = FALSE, validation = "CV")
summary(pcr.fit.nba)
pcr.fit.nba <- pcr(salary ~ ., data = nba_scaled, scale = FALSE, validation = "CV")
summary(pcr.fit.nba)
validationplot(pcr.fit.nba, val.type = "MSEP")
set.seed(123)
train.nba <- sample(1:nrow(nba_scaled), nrow(nba_scaled) / 2)
test.nba <- (-train.nba)
pcr.fit.nba <- pcr(salary ~ ., data = nba_scaled, subset = train.nba, validation = "CV" )
validationplot(pcr.fit.nba, val.type = "MSEP")
pcr.pred.nba <- predict(pcr.fit.nba, nba_scaled[test.nba, ], ncomp = 10)
mean((pcr.pred.nba - nba_scaled[test.nba, c("salary")]) ^ 2)
test.nba
train.nba
nba_scaled[test.nba, ]
Hitters[test, ]
test
Hitters[test, ]
train.nba <- sample(c(TRUE, FALSE), nrow(nba_scaled), replace = TRUE)
test.nba <- (!train.nba)
train.nba
test.nba
pcr.fit.nba <- pcr(salary ~ ., data = nba_scaled, subset = train.nba, validation = "CV" )
validationplot(pcr.fit.nba, val.type = "MSEP")
nba_scaled[test.nba, ]
test.nba
nba_scaled[train.nba, ]
View(nba_scaled)
View(nba)
nba_scaled = nba %>% mutate_at(vars(-Pos), scale)
View(nba_scaled)
View(nba)
nba[train.nba, ]
train.nba <- sample(c(TRUE, FALSE), nrow(nba), replace = TRUE)
test.nba <- (!train.nba)
pcr.fit.nba <- pcr(salary ~ ., data = nba, subset = train.nba, scale = TRUE, validation = "CV" )
validationplot(pcr.fit.nba, val.type = "MSEP")
pcr.pred.nba <- predict(pcr.fit.nba, nba[test.nba, ], ncomp = 15)
mean((pcr.pred.nba - nba[test.nba, c("salary")]) ^ 2)
pcr.pred.nba
nba[test.nba, c("salary")]
type(pcr.pred.nba)
typeof(pcr.pred.nba)
typeof(test.nba)
nba[test.nba, ]
typeof(nba)
nba = as.data.frame(nba)
nba[test.nba, ]
set.seed(123)
train.nba <- sample(c(TRUE, FALSE), nrow(nba), replace = TRUE)
test.nba <- (!train.nba)
pcr.fit.nba <- pcr(salary ~ ., data = nba, subset = train.nba, scale = TRUE, validation = "CV" )
validationplot(pcr.fit.nba, val.type = "MSEP")
pcr.pred.nba <- predict(pcr.fit.nba, nba[test.nba, ], ncomp = 9)
mean((pcr.pred.nba - nba[test.nba, c("salary")]) ^ 2)
pcr.fit <- pcr(salary ~ ., data = nba, scale = TRUE, ncomp = 9)
pcr.fit.nba <- pcr(salary ~ ., data = nba, scale = TRUE, ncomp = 9)
summary(pcr.fit.nba)
pcr.pred.nba
nba[test.nba, c("salary")]
mean((pcr.pred.nba - nba[test.nba, c("salary")]) ^ 2)
pcr.fit.nba <- pcr(salary ~ ., data = nba, scale = TRUE, ncomp = 9)
summary(pcr.fit.nba)
nba <- read_csv("nba_player_stats_salary_2019_2020.csv")
View(nba)
nba <- na.omit(nba)
nba <- nba %>% rename(salary = mean_salary_2019_2020) %>%
mutate(Pos = str_remove(string = Pos, pattern = "\\-.*"))
dim(nba)
View(nba)
# Eliminamos jugador y equipo
nba <- nba %>% select(-c(Player, Tm))
View(nba)
# Modelo lineal
modelo_lineal = nba %>% lm(formula = salary ~ ., data = .)
summary(modelo_lineal)
# Eliminamos jugador y equipo
dx_nba <- nba %>% select(-c(Player, Tm))
nba <- read_csv("nba_player_stats_salary_2019_2020.csv")
nba <- na.omit(nba)
nba <- nba %>% rename(salary = mean_salary_2019_2020) %>%
mutate(Pos = str_remove(string = Pos, pattern = "\\-.*"))
dim(nba)
# Eliminamos jugador y equipo
dx_nba <- nba %>% select(-c(Player, Tm))
# Modelo lineal
modelo_lineal = dx_nba %>% lm(formula = salary ~ ., data = .)
summary(modelo_lineal)
nba_scaled = dx_nba %>% mutate_at(vars(-Pos), scale)
# Nuevo modelo lineal
modelo_lineal_scal = nba_scaled %>% lm(formula = salary~., data = .)
modelos_lineales = list(lineal = modelo_lineal, lineal_escalado = modelo_lineal_scal)
map_dfr(.x = modelos_lineales, .f = glance, .id="modelo") %>%
select(modelo, r.squared, adj.r.squared, p.value)
View(Hitters)
x <- model.matrix(salary ~ ., dx_nba)[, -1]
View(x)
View(dx_nba)
y <- dx_nba$salary
train <- sample(1:nrow(x), nrow(x) / 2)
train
test <- (-train)
test
y.test <- y[test]
y.test
View(dx_nba)
y
#If we had instead simply fit a model with just an intercept, we would have
#predicted each test observation using the mean of the training observations
#in that case, we could compute the test set MSE like this:
mean((mean(y[train]) - y.test) ^ 2)
nba <- read_csv("nba_player_stats_salary_2019_2020.csv")
nba <- na.omit(nba)
nba <- nba %>% rename(salary = mean_salary_2019_2020) %>%
mutate(Pos = str_remove(string = Pos, pattern = "\\-.*"))
dim(nba)
nba %>%
select_if(is.numeric) %>% # selección variables numéricas
ggcorr(., layout.exp = 5, hjust = 1, size = 3.5, nbreaks = 5, color = "grey50") + # graficamos correlacion pearson
labs(title='Correlograma de variables cuantitativas')
# Eliminamos jugador y equipo
dx_nba <- nba %>% select(-c(Player, Tm))
dx_nba <- as.data.frame(dx_nba)
# Modelo lineal
modelo_lineal = dx_nba %>% lm(formula = salary ~ ., data = .)
summary(modelo_lineal)
nba_scaled = dx_nba %>% mutate_at(vars(-Pos), scale)
# Nuevo modelo lineal
modelo_lineal_scal = nba_scaled %>% lm(formula = salary~., data = .)
modelos_lineales = list(lineal = modelo_lineal, lineal_escalado = modelo_lineal_scal)
map_dfr(.x = modelos_lineales, .f = glance, .id="modelo") %>%
select(modelo, r.squared, adj.r.squared, p.value)
set.seed(123)
x <- model.matrix(salary ~ ., dx_nba)[, -1]
y <- dx_nba$salary
train <- sample(1:nrow(x), nrow(x) / 2)
test <- (-train)
y.test <- y[test]
pcr.fit.nba <- pcr(salary ~ ., data = dx_nba, scale = TRUE, validation = "CV")
summary(pcr.fit.nba)
validationplot(pcr.fit.nba, val.type = "MSEP")
pcr.fit.nba <- pcr(salary ~ ., data = dx_nba, subset = train, scale = TRUE, validation = "CV" )
validationplot(pcr.fit.nba, val.type = "MSEP")
pcr.pred.nba <- predict(pcr.fit.nba, dx_nba[test, ], ncomp = 30)
mean((pcr.pred.nba - y.test) ^ 2)
#If we had instead simply fit a model with just an intercept, we would have
#predicted each test observation using the mean of the training observations
#in that case, we could compute the test set MSE like this:
mean((mean(y[train]) - y.test) ^ 2)
pcr.fit.nba <- pcr(salary ~ ., data = dx_nba, scale = TRUE, ncomp = 30)
summary(pcr.fit.nba)
pcr.pred.nba
y.test
y.test[0]
y.test[1]
pcr.pred.nba[1]
y.test[2]
pcr.pred.nba[2]
y.test[3]
pcr.pred.nba[3]
eval_outliers_rob <- broom::augment(pcr.fit.nba, dx_nba[test, ])
modelo_lineal_train = dx_nba[train, ] %>% lm(formula = salary~., data = .)
eval_outliers_rob <- broom::augment(modelo_lineal_train, dx_nba[test, ])
metricas_outliers_rob = metrics(data = eval_outliers_rob, truth = peso, estimate = .fitted) %>% mutate(.estimate = round(.estimate, 4))
eval_outliers_rob <- broom::augment(modelo_lineal_train, dx_nba[test, ])
metricas_outliers_rob = metrics(data = eval_outliers_rob, truth = salary, estimate = .fitted) %>% mutate(.estimate = round(.estimate, 4))
metricas_outliers_rob
eval_modelo_lineal <- broom::augment(modelo_lineal_train, dx_nba[test, ])
metricas_modelo_lineal = metrics(data = eval_modelo_lineal, truth = salary, estimate = .fitted)
metricas_modelo_lineal
1.28e+7
1.28e+7 ^ 2
mean((pcr.pred.nba - y.test) ^ 2)
mean((pcr.pred.nba - y.test) ^ 2) ^ 0.5
modelo_lineal_train = dx_nba %>% lm(formula = salary~., data = .)
eval_modelo_lineal <- broom::augment(modelo_lineal_train, dx_nba[test, ])
modelo_lineal_train = dx_nba[train, ] %>% lm(formula = salary~., data = .)
eval_modelo_lineal <- broom::augment(modelo_lineal_train, dx_nba[test, ])
metricas_modelo_lineal = metrics(data = eval_modelo_lineal, truth = salary, estimate = .fitted)
metricas_modelo_lineal
modelo_lineal_train = lm(formula = salary~., data = dx_nba)
eval_modelo_lineal <- broom::augment(modelo_lineal_train, dx_nba[test, ])
eval_modelo_lineal <- broom::augment(modelo_lineal_train, dx_nba)
metricas_modelo_lineal = metrics(data = eval_modelo_lineal, truth = salary, estimate = .fitted)
metricas_modelo_lineal
mean((pcr.pred.nba - y.test) ^ 2)
mean((pcr.pred.nba - y.test) ^ 2) ^ 0.5
5.912484e+13
modelo_lineal_train = dx_nba[train, ] %>% lm(formula = salary~., data = .)
eval_modelo_lineal <- broom::augment(modelo_lineal_train, dx_nba[test, ])
metricas_modelo_lineal = metrics(data = eval_modelo_lineal, truth = salary, estimate = .fitted)
metricas_modelo_lineal
1.28e+7
View(dx_nba)
eval_modelo_lineal
View(eval_modelo_lineal)
View(eval_modelo_lineal)
mean((eval_modelo_lineal$.fitted - y.test) ^ 2)
mean((pcr.pred.nba - y.test) ^ 2)
